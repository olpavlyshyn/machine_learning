{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('static/datasets/email/ex6data1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['X'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b6782c1820>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXVklEQVR4nO3dfazcVZ3H8fdnS9VuYG1CbyL0wctGQ+IDUrgQTBPDrTGwQgpRVruJD2w0jVUjroammPTuWv+wQuIaJdF0wSz4sNAgaSpCCElvskLWyi0tIBRMVzFwZeUKFiTbZSn73T9mbplOZ+7MnfnN7/wePq/kpvNwOvO9v3a+c37n9z3nKCIwM7Py+4vUAZiZWTac0M3MKsIJ3cysIpzQzcwqwgndzKwiTkn1xitWrIjx8fFUb29mVkr79+//Y0SMdXouWUIfHx9nZmYm1dubmZWSpN91e85DLmZmFeGEbmZWEU7oZmYV4YRuZlYRTuhmZhXhhG5WdNdfD9PTJz42Pd143KyFE7pZ0V1wAXzkI68n9enpxv0LLkgblxWOE7rVSxl7u5OTsGtXI4lPTTX+3LWr8bhZCyd0q5ey9nYnJ2HzZvja1xp/OplbB07oVi9l7e1OT8N3vwvbtjX+bD/LGLUyntnUkBO61U/ZervzZxG7dsH27a9/IeWZ1Mt6ZlMzTuhWP6l7u4v14IMnnkXMn2U8+GB+MZT1zKZmlGpP0YmJifDiXJa71t7u5OTJ921hU1ONM5tt2xpnC5Y7SfsjYqLTc3330CUtkXRA0l0dnrta0pykg82fTw8TsNnIFKG3W1ZlO7OpocUsn3sNcAj4qy7P3x4Rnx8+JLMR2rLl5McmJ90776X9TGZy0mc2BdRXD13SKuAy4KbRhmNmheQzm1Lot4f+LWALcNoCbT4s6X3Ar4F/iIin2xtI2gRsAlizZs3iIjWzdHxmUwo9e+iSLgeei4j9CzT7KTAeEecA9wG3dGoUETsjYiIiJsbGOu6gZGZmA+pnyGUdsEHSU8BtwHpJP2xtEBHPR8Qrzbs3AednGqWZmfXUM6FHxHURsSoixoGNwN6I+FhrG0lntNzdQOPiqZmZ5WjgTaIlbQdmImIP8AVJG4BjwAvA1dmEZ2Zm/fLEIrOsXH99Yyp864XC6elGJUini4pmA8hkYpGZ9eD1TiyxgYdczKxN63onmzc3ZlN64o3lyD10syyVbSVHqxQndLMseb0TS8gJ3SwrRVi33GrNCd0sK17vZGHe9WjknNDNsrJly8lj5pOTLlmc5yqgkXOVi5nlw1VAI+ceupnlx1VAI+WEbmb5cRXQSDmhm1k+XAU0ck7oZpYPVwGNnBfnMjPLQk6Ls3lxLjOzUStAWabLFs3MslCAskz30M3MspK4LNMJ3cwsK4nLMsuT0L0OhJkVWQHKMsuT0AtwwcHMrKsClGWWq2xxPol7HQgzq6nqlC16HQhbLA/VWY2UK6F7HQhbLA/Vvc5fbpVXnoRegAsOVkKttcFTU6//H6rj2Z2/3CqvPAm9ABccrKQ8VNfgL7fK6/uiqKQlwAwwGxGXtz33RuBW4HzgeeCjEfHUQq/ntVwsN76YfqKpqcaX27ZtjbNdK5WsLopeAxzq8tyngD9FxNuAfwa+sbgQzUbEQ3Un8nWoSusroUtaBVwG3NSlyRXALc3bdwDvl6ThwzMbkofqXucvt8rrd3GubwFbgNO6PL8SeBogIo5JehE4HfhjayNJm4BNAGvWrBkgXLNF6rRs6eRkPYdcFvpyq+PxqKCeCV3S5cBzEbFf0sXDvFlE7AR2QmMMfZjXMrNF8pdb5fUz5LIO2CDpKeA2YL2kH7a1mQVWA0g6BXgzjYujZmaWk54JPSKui4hVETEObAT2RsTH2prtAT7ZvH1Vs4174GY2PE+I6tvAdeiStkva0Lx7M3C6pMPAl4CtWQRnZuYJUf0r1+JcZlZPo5hLkNMeoFmrzuJcZkXn4YHRGMVs3wr2/J3QzbJUwSRRCKOYEFXFpRAiIsnP+eefH2aVtHdvxIoVEdu2Nf7cuzd1ROU2fzznj2P7/WFt2xYBjT9LAJiJLnnVPXSzrHkxsGyNcrZvxZZC8EVRs6x5MbByaF0KYXLy5PsF5YuiZnnxeinlUcF1ftxDN8tSSUvhrDwW6qE7oZuZlYiHXMzMasAJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M3MKsIJ3cysIpzQzcwqwgndzKwinNDNzCrCCd3MrCKc0M2sM++PWjpO6GbWmfdHLZ1TUgdgZgXVuomyd18qBSd069vuA7PccO+T/P7IUc5cvoxrLzmbK9euTB2WjVLr/qjbtjmZF1zPIRdJb5L0S0kPS3pM0lc7tLla0pykg82fT48mXEtl94FZrrvzUWaPHCWA2SNHue7OR9l9YDZ1aDbKse6KbaJcdf2Mob8CrI+I9wDnApdKuqhDu9sj4tzmz01ZBmnp3XDvkxx99bUTHjv66mvccO+TiSKy40Y11u39UUunZ0KPhpebd5c2f9LsW2fJ/P7I0UU9bjlqHeuemspu5/oKbqJcdX1VuUhaIukg8BxwX0Ts69Dsw5IekXSHpNVdXmeTpBlJM3Nzc4NHbbk7c/myRT1uOWsd6968OZux7i1bTn6dyUlvdl1gfSX0iHgtIs4FVgEXSnpXW5OfAuMRcQ5wH3BLl9fZGRETETExNjY2RNiWt2svOZtlS5ec8NiypUu49pKzE0VkJ/BYt7HIOvSIOAJMA5e2Pf58RLzSvHsTcH4m0VlhXLl2JV//0LtZuXwZAlYuX8bXP/RuV7kUQR3GusswyakAMfZT5TImaXnz9jLgA8ATbW3OaLm7ATiUYYxWEFeuXckDW9fz2x2X8cDW9U7mRVGHse4yTHIqQIyKWPj6pqRzaAyhLKHxBbArIrZL2g7MRMQeSV+nkciPAS8AmyPiia4vCkxMTMTMzEwWv0OtuTbcamM+QRZ5klMOMUraHxETHZ/rldBHxQl9ePO14a3lhMuWLvFQiFXX1NTrk5y2b08dTWcjjnGhhO61XEqs7LXhuw/Msm7HXs7a+jPW7djrSUq2sDJc+E0co6f+l1iZa8Pbzy7mZ54CPruwk7Ve+J2cbPxkVW+flQLE6B56iZW5NrzsZxeWszJc+C1AjB5DL7Eyj6GftfVnHacbC/jtjsvyDscGcf31jQqO1t7n9HQjgXny0ch4DL2iylwbXuazC2sqQJmenchj6CV35dqVpUjg7a695OyOZxeeeVoiXi+9cJzQLYn5LyHX0Jec10svFCd0S6asZxfWor1Mb766w5LwGLqZDaYOa8iUjBO6mQ2mAGV6diKXLVqteS0cKxuXLdqi1WFavvdJtVzlsLyuE7qdpC6JzrNVLVc51O07odtJ6pLoyrwWjpXQqPZ+beGEbiepS6LzbFXL3Sj2fm3hhG4nqUui8z6plrsRL6/rhG4nqUuiK/NaODaA1Ht+5lC375midpI6Tcv3bNUamb8oOT9u3Zpg87BQ3X5GQy+uQzez+ijDvqQ9uA7dCqcOde61lHpYo5cRX5RMzQndcleXOvdaKvoa6WXYl3QITuiWu7rUuddSDrXWA6vBYmJO6CVSlWGKutS511ZRhzVqsJiYq1xKon3/0PlhCqB0VRpnLl/GbIfkXbU699oq6hrpnfY5LUpsGenZQ5f0Jkm/lPSwpMckfbVDmzdKul3SYUn7JI2PJNoa6NYLr9IwRV3q3GupBsMaRdZPD/0VYH1EvCxpKXC/pHsi4hctbT4F/Cki3iZpI/AN4KMjiLfSFuqFV2mYok517rWTQ621dbeoOnRJfwncD2yOiH0tj98L/FNE/IekU4D/AsZigRd3HfrJ1u3Y23EoYmVzKKLbcw9sXT/y2MysGIauQ5e0RNJB4DngvtZk3rQSeBogIo4BLwKnd3idTZJmJM3Mzc0t4leoh4V64R6mKKeqXMi2cugroUfEaxFxLrAKuFDSuwZ5s4jYGRETETExNjY2yEtU2kKLYnndkfJxvb3lbVFVLhFxRNI0cCnwq5anZoHVwDPNIZc3A89nFmVNXHvJ2SeMocOJvfCs1x2pw/ZrKX/HhS5kV+04WzH0U+UyJml58/Yy4APAE23N9gCfbN6+Cti70Pi5dZZnL7wOvcfUv2OVLmRbOfTTQz8DuEXSEhpfALsi4i5J24GZiNgD3Az8QNJh4AVg48girri8Vv+rQ+8x9e+YZb19Hc6mbHg9E3pEPAKs7fD4VMvt/wH+NtvQbJTq0HtM/Tv2GkLrV5Umldloeep/TdVhV6LUv2NWQ2hVmlSWRNFXgMyQE3pN1aEMsgi/45VrV/LA1vX8dsdlPLB1/UA96tRnGqVX9BUgM+S1XGqqDrM1q/I7eu2bIbWuAFnijS364R2LzAqufQwdGmcanoewSFNTjRUgt21rrDNTUt6xyKzEPKksAxXf2GKeh1ysVspa/ufNrIfQugLk/HK5Rdp4I0PuoVttpJ5oZInUYGOLeR5Dt9pYaDVLr1hpZeExdDNc/mfV54RutZF6opHZqDmhW23kNdHIa6BbKq5ysdylqjTJY6KR112xlJzQS6yMJXipE96oy/9Sr/Bo9eYhl5Iqawle1Rea8oVXS8kJvaTKmhirnvAGvfDqcXfLghN6SZU1MVa90mSQC68pz7b8RVItTuglVdbEWIQlbUdpkHVXUp1tlXXYzrrzRdGSymo3nLxVZUnbhSz2wmuqsy1fwK0eJ/TEBq1UKXNi9EJTJ0q13nlZh+2sOyf0hIYt4XNirIZUZ1veOKN6PIaeUFkrVSxbqdY7r/r1jDpyDz0hn/LavBRnW2UetrPOnNAT8imvpeZhu2rxkEtCPuU1syz1TOiSVkualvS4pMckXdOhzcWSXpR0sPkzNZpwq8V7RZpZlvoZcjkGfDkiHpJ0GrBf0n0R8Xhbu59HxOXZh1htPuU1s6z07KFHxLMR8VDz9p+BQ4AzkJlZwSxqDF3SOLAW2Nfh6fdKeljSPZLe2eXvb5I0I2lmbm5u8dGamVlXfSd0SacCPwG+GBEvtT39EPDWiHgP8B1gd6fXiIidETERERNjY2MDhmxmZp30ldAlLaWRzH8UEXe2Px8RL0XEy83bdwNLJa3INFIzM1tQz4uikgTcDByKiG92afMW4A8REZIupPFF8XymkVrtlHFHJrOU+qlyWQd8HHhU0sHmY18B1gBExPeAq4DNko4BR4GNERHZh2t1kXqruiLwF5otVs+EHhH3A+rR5kbgxqyCMqv70q7+QrNBeOq/FVJe69wUtRdc9y80G4yn/lsh5bEjU5F37PHCbTYIJ3Q7QVH2mMxjnZsiL19c1i0GLS0ndDuuSD3WPNa5KXIv2Au32SA8hm7HFW3cdtTr3BR5+eIyrVVe1OsQdeSEbscVucc6CkXfaLsMC7e5GqdYPORix9Vt3NbLFw+vyNch6sg9dDuu6D3WUShDL7jI6nZWV3Tuodtx7rHaYtXtrK7o3EO3E7jHaotRx7O6InNCNxtSnas8ylSNUwdO6GZDcJWHz+qKxGPoZkNwlYcViRO62RBc5WFF4oRuNgRXeViROKGbDcFrrliR+KKo2RBc5WFF4oRuNiRXeVhReMjFzKwinNDNzCrCQy5WSXWevWn15YRulVP22Zv+MrJBOaHbSKVITkXbeWkxyv5lZGl5DN1GJtUepWWevemlBGwYPRO6pNWSpiU9LukxSdd0aCNJ35Z0WNIjks4bTbhWJqmSU5lnb5b5y8jS66eHfgz4ckS8A7gI+Jykd7S1+Rvg7c2fTcB3M43SSilVcirz7M0yfxlZej0TekQ8GxEPNW//GTgEtA/mXQHcGg2/AJZLOiPzaK1UUiWnMu+8lMeX0e4Ds6zbsZeztv6MdTv2jnwIzPKzqIuiksaBtcC+tqdWAk+33H+m+dizbX9/E40ePGvWrFlkqFY2KXezKevszVEvJeCLrtXWd0KXdCrwE+CLEfHSIG8WETuBnQATExMxyGtYeXidk8GM8suozBVA1ltfCV3SUhrJ/EcRcWeHJrPA6pb7q5qPWc2VtadcVb7oWm39VLkIuBk4FBHf7NJsD/CJZrXLRcCLEfFsl7ZmlogvulZbP1Uu64CPA+slHWz+fFDSZyR9ptnmbuA3wGHgX4DPjiZcMxtGmSuArLeeQy4RcT+gHm0C+FxWQZnZaPi6RrV56r9Zzfi6RnV56r+ZWUU4oZuZVYQTuplZRTihm5lVhBO6mVlFOKGbmVWEE7qZWUU4oZuZVYQTuplZRTihm5lVhBO6mVlFOKGbmVWEE7qZWUU4oZuZVYQTuplZRXg9dLMudh+Y9UYQVipO6GYd7D4wy3V3PsrRV18DYPbIUa6781EAJ3UrLA+5mHVww71PHk/m846++ho33PtkoojMenNCN+vg90eOLupxsyJwQjfr4Mzlyxb1uFkROKGbdXDtJWezbOmSEx5btnQJ115ydqKIzHrzRVGzDuYvfLrKxcrECd2siyvXrnQCt1LpOeQi6fuSnpP0qy7PXyzpRUkHmz9T2YdpZma99NND/1fgRuDWBdr8PCIuzyQiMzMbSM8eekT8O/BCDrGYmdkQsqpyea+khyXdI+md3RpJ2iRpRtLM3NxcRm9tZmaQTUJ/CHhrRLwH+A6wu1vDiNgZERMRMTE2NpbBW5uZ2TxFRO9G0jhwV0S8q4+2TwETEfHHHu3mgN/1eLkVwIKvk0hR4wLHNqiixlbUuMCxDWrY2N4aER17xEOXLUp6C/CHiAhJF9Lo9T/f6+91C6jttWciYmLYGLNW1LjAsQ2qqLEVNS5wbIMaZWw9E7qkfwMuBlZIegb4R2ApQER8D7gK2CzpGHAU2Bj9dPvNzCxTPRN6RPxdj+dvpFHWaGZmCRV9LZedqQPooqhxgWMbVFFjK2pc4NgGNbLY+rooamZmxVf0HrqZmfXJCd3MrCKSJ3RJl0p6UtJhSVs7PP9GSbc3n9/XrIkvSmxXS5prWZjs0znF1WvBNEn6djPuRySdl0dcfcaWZDE3SaslTUt6XNJjkq7p0CbJcesztlTH7U2SftmcCf6YpK92aJPkM9pnbEk+o833XiLpgKS7Ojw3mmMWEcl+gCXAfwJ/DbwBeBh4R1ubzwLfa97eCNxeoNiuBm5McNzeB5wH/KrL8x8E7gEEXATsK1BsF9OYpJb3MTsDOK95+zTg1x3+PZMctz5jS3XcBJzavL0U2Adc1NYm1We0n9iSfEab7/0l4Med/t1GdcxS99AvBA5HxG8i4n+B24Ar2tpcAdzSvH0H8H5JKkhsSUTvBdOuAG6Nhl8AyyWdUZDYkoiIZyPioebtPwOHgPbFzpMctz5jS6J5LF5u3l3a/GmvpEjyGe0ztiQkrQIuA27q0mQkxyx1Ql8JPN1y/xlO/o98vE1EHANeBE4vSGwAH26ent8haXUOcfWj39hT6Wsxt1Fpnt6updGja5X8uC0QGyQ6bs2hg4PAc8B9EdH1uOX8Ge0nNkjzGf0WsAX4vy7Pj+SYpU7oZfdTYDwizgHu4/VvXOuu78XcRkHSqcBPgC9GxEt5vncvPWJLdtwi4rWIOBdYBVwoqeeaTnnpI7bcP6OSLgeei4j9o36vdqkT+izQ+o25qvlYxzaSTgHeTB9rxeQRW0Q8HxGvNO/eBJyfQ1z96Oe4JhERL82fJkfE3cBSSSvyeG9JS2kkzB9FxJ0dmiQ7br1iS3ncWmI4AkwDl7Y9leoz2jO2RJ/RdcAGNRYqvA1YL+mHbW1GcsxSJ/QHgbdLOkvSG2hcHNjT1mYP8Mnm7auAvdG8kpA6trbx1Q00xj6LYA/wiWbVxkXAixHxbOqgoLGY2/xYoRaxmFsG7yvgZuBQRHyzS7Mkx62f2BIetzFJy5u3lwEfAJ5oa5bkM9pPbCk+oxFxXUSsiohxGnljb0R8rK3ZSI5Z0k2iI+KYpM8D99KoKvl+RDwmaTswExF7aPxH/4GkwzQutm0sUGxfkLQBONaM7eo8YlPvBdPuplGxcRj4b+Dv84irz9hSLea2Dvg48GhzzBXgK8CalthSHbd+Ykt13M4AbpG0hMaXyK6IuKsIn9E+Y0vyGe0kj2Pmqf9mZhWResjFzMwy4oRuZlYRTuhmZhXhhG5mVhFO6GZmFeGEbmZWEU7oZmYV8f+IJvaRgSg9FgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data = np.concatenate((X, y), axis=1)\n",
    "first_class = plot_data[plot_data[:,2] == 1]\n",
    "second_class = plot_data[plot_data[:,2] == 0]\n",
    "plt.plot(second_class[:, 0], second_class[:, 1], 'o')\n",
    "plt.plot(first_class[:, 0], first_class[:, 1], 'x', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmTrain(X, Y, C, kernelFunction, tol=1e-3, max_passes=5, args=()):\n",
    "    \"\"\"\n",
    "    Trains an SVM classifier using a  simplified version of the SMO algorithm.\n",
    "    Parameters\n",
    "    ---------\n",
    "    X : numpy ndarray\n",
    "        (m x n) Matrix of training examples. Each row is a training example, and the\n",
    "        jth column holds the jth feature.\n",
    "    Y : numpy ndarray\n",
    "        (m, ) A vector (1-D numpy array) containing 1 for positive examples and 0 for negative examples.\n",
    "    C : float\n",
    "        The standard SVM regularization parameter.\n",
    "    kernelFunction : func\n",
    "        A function handle which computes the kernel. The function should accept two vectors as\n",
    "        inputs, and returns a scalar as output.\n",
    "    tol : float, optional\n",
    "        Tolerance value used for determining equality of floating point numbers.\n",
    "    max_passes : int, optional\n",
    "        Controls the number of iterations over the dataset (without changes to alpha)\n",
    "        before the algorithm quits.\n",
    "    args : tuple\n",
    "        Extra arguments required for the kernel function, such as the sigma parameter for a\n",
    "        Gaussian kernel.\n",
    "    Returns\n",
    "    -------\n",
    "    model :\n",
    "        The trained SVM model.\n",
    "    Notes\n",
    "    -----\n",
    "    This is a simplified version of the SMO algorithm for training SVMs. In practice, if\n",
    "    you want to train an SVM classifier, we recommend using an optimized package such as:\n",
    "    - LIBSVM   (http://www.csie.ntu.edu.tw/~cjlin/libsvm/)\n",
    "    - SVMLight (http://svmlight.joachims.org/)\n",
    "    - scikit-learn (http://scikit-learn.org/stable/modules/svm.html) which contains python wrappers\n",
    "    for the LIBSVM library.\n",
    "    \"\"\"\n",
    "    # make sure data is signed int\n",
    "    Y = Y.astype(int)\n",
    "    # Dataset size parameters\n",
    "    m, n = X.shape\n",
    "\n",
    "    passes = 0\n",
    "    E = np.zeros(m)\n",
    "    alphas = np.zeros(m)\n",
    "    b = 0\n",
    "\n",
    "    # Map 0 to -1\n",
    "    Y[Y == 0] = -1\n",
    "\n",
    "    # Pre-compute the Kernel Matrix since our dataset is small\n",
    "    # (in practice, optimized SVM packages that handle large datasets\n",
    "    # gracefully will **not** do this)\n",
    "\n",
    "    # We have implemented the optimized vectorized version of the Kernels here so\n",
    "    # that the SVM training will run faster\n",
    "    if kernelFunction.__name__ == 'linearKernel':\n",
    "        # Vectorized computation for the linear kernel\n",
    "        # This is equivalent to computing the kernel on every pair of examples\n",
    "        K = np.dot(X, X.T)\n",
    "    elif kernelFunction.__name__ == 'gaussianKernel':\n",
    "        # vectorized RBF Kernel\n",
    "        # This is equivalent to computing the kernel on every pair of examples\n",
    "        X2 = np.sum(X**2, axis=1)\n",
    "        K = X2 + X2[:, None] - 2 * np.dot(X, X.T)\n",
    "\n",
    "        if len(args) > 0:\n",
    "            K /= 2*args[0]**2\n",
    "\n",
    "        K = np.exp(-K)\n",
    "    else:\n",
    "        K = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(i, m):\n",
    "                K[i, j] = kernelFunction(X[i, :], X[j, :])\n",
    "                K[j, i] = K[i, j]\n",
    "\n",
    "    while passes < max_passes:\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(m):\n",
    "            E[i] = b + np.sum(alphas * Y * K[:, i]) - Y[i]\n",
    "\n",
    "            if (Y[i]*E[i] < -tol and alphas[i] < C) or (Y[i]*E[i] > tol and alphas[i] > 0):\n",
    "                # select the alpha_j randomly\n",
    "                j = np.random.choice(list(range(i)) + list(range(i+1, m)), size=1)[0]\n",
    "\n",
    "                E[j] = b + np.sum(alphas * Y * K[:, j]) - Y[j]\n",
    "\n",
    "                alpha_i_old = alphas[i]\n",
    "                alpha_j_old = alphas[j]\n",
    "\n",
    "                if Y[i] == Y[j]:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "\n",
    "                if L == H:\n",
    "                    continue\n",
    "\n",
    "                eta = 2 * K[i, j] - K[i, i] - K[j, j]\n",
    "\n",
    "                # objective function positive definite, there will be a minimum along the direction\n",
    "                # of linear equality constrain, and eta will be greater than zero\n",
    "                # we are actually computing -eta here (so we skip of eta >= 0)\n",
    "                if eta >= 0:\n",
    "                    continue\n",
    "\n",
    "                alphas[j] -= Y[j] * (E[i] - E[j])/eta\n",
    "                alphas[j] = max(L, min(H, alphas[j]))\n",
    "\n",
    "                if abs(alphas[j] - alpha_j_old) < tol:\n",
    "                    alphas[j] = alpha_j_old\n",
    "                    continue\n",
    "                alphas[i] += Y[i]*Y[j]*(alpha_j_old - alphas[j])\n",
    "\n",
    "                b1 = b - E[i] - Y[i]*(alphas[i] - alpha_i_old) * K[i, j] \\\n",
    "                     - Y[j] * (alphas[j] - alpha_j_old) * K[i, j]\n",
    "\n",
    "                b2 = b - E[j] - Y[i]*(alphas[i] - alpha_i_old) * K[i, j] \\\n",
    "                     - Y[j] * (alphas[j] - alpha_j_old) * K[j, j]\n",
    "\n",
    "                if 0 < alphas[i] < C:\n",
    "                    b = b1\n",
    "                elif 0 < alphas[j] < C:\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2)/2\n",
    "\n",
    "                num_changed_alphas += 1\n",
    "        if num_changed_alphas == 0:\n",
    "            passes += 1\n",
    "        else:\n",
    "            passes = 0\n",
    "\n",
    "    idx = alphas > 0\n",
    "    model = {'X': X[idx, :],\n",
    "             'y': Y[idx],\n",
    "             'kernelFunction': kernelFunction,\n",
    "             'b': b,\n",
    "             'args': args,\n",
    "             'alphas': alphas[idx],\n",
    "             'w': np.dot(alphas * Y, X)}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearKernel(x1, x2):\n",
    "    \"\"\"\n",
    "    Returns a linear kernel between x1 and x2.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1 : numpy ndarray\n",
    "        A 1-D vector.\n",
    "    x2 : numpy ndarray\n",
    "        A 1-D vector of same size as x1.\n",
    "    Returns\n",
    "    -------\n",
    "    : float\n",
    "        The scalar amplitude.\n",
    "    \"\"\"\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeBoundaryLinear(X, y, model):\n",
    "    \"\"\"\n",
    "    Plots a linear decision boundary learned by the SVM.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        (m x 2) The training data with two features (to plot in a 2-D plane).\n",
    "    y : array_like\n",
    "        (m, ) The data labels.\n",
    "    model : dict\n",
    "        Dictionary of model variables learned by SVM.\n",
    "    \"\"\"\n",
    "    w, b = model['w'], model['b']\n",
    "    xp = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
    "    yp = -(w[0] * xp + b)/w[1]\n",
    "\n",
    "    plotData(X, y)\n",
    "    pyplot.plot(xp, yp, '-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(linearKernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_sentiment",
   "language": "python",
   "name": "twitter_sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
